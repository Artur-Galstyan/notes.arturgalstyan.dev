import { c as createComponent, m as maybeRenderHead, f as renderTemplate, a as createAstro, r as renderComponent, g as renderScript, b as addAttribute, d as renderHead, e as renderSlot, u as unescapeHTML } from './astro/server_jCnFmPOC.mjs';
import 'kleur/colors';
import 'clsx';
/* empty css                         */

const $$Navbar = createComponent(($$result, $$props, $$slots) => {
  return renderTemplate`${maybeRenderHead()}<nav class="bg-base-100 my-8"> <div class="navbar-start"> <div class="navbar-start"> <a href="/" class="normal-case text-2xl font-bold border border-base-300 p-4 rounded-lg shadow-sm">Artur's Notes</a> </div> </div> </nav>`;
}, "/Users/arturgalstyan/Workspace/notes.arturgalstyan.dev/src/components/Navbar.astro", void 0);

const $$Astro$1 = createAstro();
const $$Index = createComponent(($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro$1, $$props, $$slots);
  Astro2.self = $$Index;
  const propsStr = JSON.stringify(Astro2.props);
  const paramsStr = JSON.stringify(Astro2.params);
  return renderTemplate`${renderComponent($$result, "vercel-analytics", "vercel-analytics", { "data-props": propsStr, "data-params": paramsStr, "data-pathname": Astro2.url.pathname })} ${renderScript($$result, "/Users/arturgalstyan/Workspace/notes.arturgalstyan.dev/node_modules/@vercel/analytics/dist/astro/index.astro?astro&type=script&index=0&lang.ts")}`;
}, "/Users/arturgalstyan/Workspace/notes.arturgalstyan.dev/node_modules/@vercel/analytics/dist/astro/index.astro", void 0);

const $$Astro = createAstro();
const $$PostLayout = createComponent(($$result, $$props, $$slots) => {
  const Astro2 = $$result.createAstro($$Astro, $$props, $$slots);
  Astro2.self = $$PostLayout;
  const { title } = Astro2.props;
  return renderTemplate`<html lang="en" data-theme="light"> <head><meta charset="utf-8"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="viewport" content="width=device-width"><meta name="generator"${addAttribute(Astro2.generator, "content")}><title>${title}</title><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css">${renderComponent($$result, "Analytics", $$Index, {})}${renderHead()}</head> <body class="bg-base-100 text-base-content"> <div class="container mx-auto px-4 py-8"> ${renderComponent($$result, "Navbar", $$Navbar, {})} </div> <div class="flex justify-center"> <article class="prose w-full"> ${renderSlot($$result, $$slots["default"])} </article> </div> <div class="h-[25rem]"></div> </body></html>`;
}, "/Users/arturgalstyan/Workspace/notes.arturgalstyan.dev/src/layouts/PostLayout.astro", void 0);

const html = () => "<h1 id=\"model-based-reinforcement-learning\">Model-Based Reinforcement Learning</h1>\n<p>Model-Based Reinforcement Learning (MBRL) is one of my favourite areas in machine learning in general. IMO, MBRL is likely going to be integral to finding AGI one day, because I believe that AGI (and intelligence in general) is simply a matter of <em>goal oriented next-state prediction</em>. I will leave this simply as an opinion and showcase my arguments for this at another time, because in this post, it’s all about coding MBRL.</p>\n<p>Btw. this is <strong>not</strong> a tutorial, but rather a workthrough of MBRL and some of the issues encountered along the way.</p>\n<p>Let’s start with the basics first. The goal of MBRL is to learn a model of the environment. The idea being that if you had a <em>perfect</em> model of the environment, then you could use that to plan a sequence of actions to get to your desired goal state. The difficulty is now to train that model, which should take in the current state <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">s</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">s</span></span></span></span> and the performed action <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> as input and predict the next state <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>s</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></mrow><annotation encoding=\"application/x-tex\">s'</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7519em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7519em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span>. For this, we will just use a simple MLP (btw. we are training on CartPole for now - gotta start somewhere, right?):</p>\n<pre class=\"astro-code astro-code-themes min-light night-owl\" style=\"background-color:#ffffff;--shiki-dark-bg:#011627;color:#24292eff;--shiki-dark:#d6deeb; overflow-x: auto;\" tabindex=\"0\" data-language=\"python\"><code><span class=\"line\"><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">class</span><span style=\"color:#6F42C1;--shiki-dark:#FFCB8B\"> DynamicsModel</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#6F42C1;--shiki-dark:#C5E478\">eqx</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#C5E478\">Module</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">):</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">    mlp</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> eqx</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">nn</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#82AAFF\">MLP</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">    n_dims</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> =</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> eqx</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">field</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#D7DBE0\">static</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#FF5874\">True</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">    n_actions</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> =</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> eqx</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">field</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#D7DBE0\">static</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#FF5874\">True</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">    def</span><span style=\"color:#6F42C1;--shiki-dark:#C5E478\"> __init__</span><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">(</span><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\"> n_dims</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\"> n_actions</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\"> key</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> PRNGKeyArray</span><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">)</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#8EACE3\">        self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">mlp </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> eqx</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">nn</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">MLP</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D7DBE0\">            in_size</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">n_dims </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">+</span><span style=\"color:#212121;--shiki-dark:#82AAFF\"> n_actions</span><span style=\"color:#212121;--shiki-dark:#D9F5DD\">,</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D7DBE0\">            out_size</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">n_dims</span><span style=\"color:#212121;--shiki-dark:#D9F5DD\">,</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D7DBE0\">            width_size</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#F78C6C\">128</span><span style=\"color:#212121;--shiki-dark:#D9F5DD\">,</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D7DBE0\">            depth</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#F78C6C\">3</span><span style=\"color:#212121;--shiki-dark:#D9F5DD\">,</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D7DBE0\">            key</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">key</span><span style=\"color:#212121;--shiki-dark:#D9F5DD\">,</span></span>\n<span class=\"line\"><span style=\"color:#212121;--shiki-dark:#D6DEEB\">        )</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#8EACE3\">        self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">n_dims </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> n_dims</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#8EACE3\">        self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">n_actions </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> n_actions</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">    def</span><span style=\"color:#6F42C1;--shiki-dark:#C5E478\"> __call__</span><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">(</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">        self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\"> x</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> Float</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">[</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#22863A;--shiki-dark:#D9F5DD\"> \"</span><span style=\"color:#22863A;--shiki-dark:#ECC48D\"> n_dims+n_actions</span><span style=\"color:#22863A;--shiki-dark:#D9F5DD\">\"</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">]</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">    )</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\"> -></span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> Float</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">[</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#22863A;--shiki-dark:#D9F5DD\"> \"</span><span style=\"color:#22863A;--shiki-dark:#ECC48D\">n_dims</span><span style=\"color:#22863A;--shiki-dark:#D9F5DD\">\"</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">]</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">        state </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> x</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">[:</span><span style=\"color:#24292EFF;--shiki-dark:#8EACE3\"> self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">n_dims</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">]</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">        delta </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#8EACE3\"> self</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">mlp</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">x</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">        return</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> state </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">+</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> delta</span></span></code></pre>\n<p>Admittedly, this is not the purest MLP, because we are using residual connections, i.e. we are trying to learn the delta between the current state and the next state. The argument is that usually there is not such a drastic change between states, thus being easier to learn the delta than the whole thing.</p>\n<p>Ok, so now we have a dynamics prediction model (we have no idea yet if it works or not though). One thing we will need for sure is <strong>data</strong>! One of the advantages of MBRL is that all data is good data, in the sense that you have no reason to throw out any data, since all the data you collect comes from the environment i.e. the ground truth.</p>\n<pre class=\"astro-code astro-code-themes min-light night-owl\" style=\"background-color:#ffffff;--shiki-dark-bg:#011627;color:#24292eff;--shiki-dark:#d6deeb; overflow-x: auto;\" tabindex=\"0\" data-language=\"python\"><code><span class=\"line\"><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">def</span><span style=\"color:#6F42C1;font-style:inherit;--shiki-dark:#82AAFF;--shiki-dark-font-style:italic\"> collect_data</span><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">(</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    env</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> gym</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">Env</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    n_episodes</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    dynamics_model</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    reward_model</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    epsilon</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> float</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> =</span><span style=\"color:#1976D2;--shiki-dark:#F78C6C\"> 0.1</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#FF9800;--shiki-dark:#7FDBCA\">    n_horizon</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> =</span><span style=\"color:#1976D2;--shiki-dark:#F78C6C\"> 10</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\">)</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\"> -></span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> list</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">[</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">tuple</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">[</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> Array</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">]]</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">    data </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D9F5DD\"> []</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">    for</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> i </span><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">in</span><span style=\"color:#6F42C1;--shiki-dark:#C5E478\"> range</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">n_episodes</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">):</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">        state</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> _ </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> env</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">reset</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">()</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">        terminated</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> truncated </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#FF5874\"> False</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#1976D2;--shiki-dark:#FF5874\"> False</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">        while</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> not</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> terminated </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">and</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> not</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> truncated</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">            if</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> random</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">random</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">()</span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\"> &#x3C;</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> epsilon</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">                action </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> env</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">action_space</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">sample</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">()</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">            else</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">:</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">                action </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#1976D2;--shiki-dark:#C5E478\"> int</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#FFFFFF\">????</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">            next_state</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> reward</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> terminated</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> truncated</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">,</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> _ </span><span style=\"color:#D32F2F;--shiki-dark:#C792EA\">=</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> env</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">step</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">action</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\">            data</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">.</span><span style=\"color:#6F42C1;--shiki-dark:#B2CCD6\">append</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">(</span><span style=\"color:#212121;--shiki-dark:#82AAFF\">(state, action, reward, next_state)</span><span style=\"color:#212121;--shiki-dark:#D6DEEB\">)</span></span>\n<span class=\"line\"><span style=\"color:#D32F2F;font-style:inherit;--shiki-dark:#C792EA;--shiki-dark-font-style:italic\">    return</span><span style=\"color:#24292EFF;--shiki-dark:#D6DEEB\"> data</span></span></code></pre>\n<p>The above function is simple: just create <code>n_episode</code> worth of data using epsilon-greedy exploration, i.e. 10 % random exploration (in this example). But what about the <code>else</code> part?</p>\n<p>In the <code>else</code> branch, we have to specify <em>how</em> we should - in general - choose actions based on our model. I alluded to this earlier, namely that we need to plan ahead. Following the <a href=\"https://www.youtube.com/watch?v=VxyhEK4yW5g\">talk from Sergey Levine</a>, you could use the cross-entropy method (CEM), which is a gradient-free planning method, although there are certainly other methods as well, such as Monte-Carlo Tree Search (MCTS). We will use CEM for now and later use MCTS to see the difference.</p>\n<h2 id=\"excursion-cross-entropy-method\">Excursion: Cross-Entropy Method</h2>";

				const frontmatter = {"layout":"../../layouts/PostLayout.astro","title":"Model-Based Reinforcement Learning Experiments","date":"2025-04-22T00:00:00.000Z"};
				const file = "/Users/arturgalstyan/Workspace/notes.arturgalstyan.dev/src/pages/posts/mb-rl-experiments.md";
				const url = "/posts/mb-rl-experiments";
				function rawContent() {
					return "   \n                                      \n                                                     \n                \n   \n\n# Model-Based Reinforcement Learning\n\nModel-Based Reinforcement Learning (MBRL) is one of my favourite areas in machine learning in general. IMO, MBRL is likely going to be integral to finding AGI one day, because I believe that AGI (and intelligence in general) is simply a matter of _goal oriented next-state prediction_. I will leave this simply as an opinion and showcase my arguments for this at another time, because in this post, it's all about coding MBRL.\n\nBtw. this is __not__ a tutorial, but rather a workthrough of MBRL and some of the issues encountered along the way.\n\nLet's start with the basics first. The goal of MBRL is to learn a model of the environment. The idea being that if you had a _perfect_ model of the environment, then you could use that to plan a sequence of actions to get to your desired goal state. The difficulty is now to train that model, which should take in the current state $s$ and the performed action $a$ as input and predict the next state $s'$. For this, we will just use a simple MLP (btw. we are training on CartPole for now - gotta start somewhere, right?):\n\n```python\nclass DynamicsModel(eqx.Module):\n    mlp: eqx.nn.MLP\n\n    n_dims: int = eqx.field(static=True)\n    n_actions: int = eqx.field(static=True)\n\n    def __init__(self, n_dims: int, n_actions: int, key: PRNGKeyArray):\n        self.mlp = eqx.nn.MLP(\n            in_size=n_dims + n_actions,\n            out_size=n_dims,\n            width_size=128,\n            depth=3,\n            key=key,\n        )\n        self.n_dims = n_dims\n        self.n_actions = n_actions\n\n    def __call__(\n        self, x: Float[Array, \" n_dims+n_actions\"]\n    ) -> Float[Array, \"n_dims\"]:\n        state = x[: self.n_dims]\n        delta = self.mlp(x)\n        return state + delta\n```\n\nAdmittedly, this is not the purest MLP, because we are using residual connections, i.e. we are trying to learn the delta between the current state and the next state. The argument is that usually there is not such a drastic change between states, thus being easier to learn the delta than the whole thing.\n\nOk, so now we have a dynamics prediction model (we have no idea yet if it works or not though). One thing we will need for sure is __data__! One of the advantages of MBRL is that all data is good data, in the sense that you have no reason to throw out any data, since all the data you collect comes from the environment i.e. the ground truth.\n\n```python\ndef collect_data(\n    env: gym.Env,\n    n_episodes: int,\n    dynamics_model,\n    reward_model,\n    epsilon: float = 0.1,\n    n_horizon: int = 10,\n) -> list[tuple[Array, Array, Array, Array]]:\n    data = []\n    for i in range(n_episodes):\n        state, _ = env.reset()\n\n        terminated, truncated = False, False\n        while not terminated and not truncated:\n            if random.random() < epsilon:\n                action = env.action_space.sample()\n            else:\n                action = int(????)\n            next_state, reward, terminated, truncated, _ = env.step(action)\n            data.append((state, action, reward, next_state))\n    return data\n```\n\nThe above function is simple: just create `n_episode` worth of data using epsilon-greedy exploration, i.e. 10 % random exploration (in this example). But what about the `else` part?\n\nIn the `else` branch, we have to specify _how_ we should - in general - choose actions based on our model. I alluded to this earlier, namely that we need to plan ahead. Following the [talk from Sergey Levine](https://www.youtube.com/watch?v=VxyhEK4yW5g), you could use the cross-entropy method (CEM), which is a gradient-free planning method, although there are certainly other methods as well, such as Monte-Carlo Tree Search (MCTS). We will use CEM for now and later use MCTS to see the difference.\n\n## Excursion: Cross-Entropy Method\n";
				}
				async function compiledContent() {
					return await html();
				}
				function getHeadings() {
					return [{"depth":1,"slug":"model-based-reinforcement-learning","text":"Model-Based Reinforcement Learning"},{"depth":2,"slug":"excursion-cross-entropy-method","text":"Excursion: Cross-Entropy Method"}];
				}

				const Content = createComponent((result, _props, slots) => {
					const { layout, ...content } = frontmatter;
					content.file = file;
					content.url = url;

					return renderTemplate`${renderComponent(result, 'Layout', $$PostLayout, {
								file,
								url,
								content,
								frontmatter: content,
								headings: getHeadings(),
								rawContent,
								compiledContent,
								'server:root': true,
							}, {
								'default': () => renderTemplate`${unescapeHTML(html())}`
							})}`;
				});

const __vite_glob_0_0 = /*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({
    __proto__: null,
    Content,
    compiledContent,
    default: Content,
    file,
    frontmatter,
    getHeadings,
    rawContent,
    url
}, Symbol.toStringTag, { value: 'Module' }));

export { $$Index as $, __vite_glob_0_0 as _, $$Navbar as a };
